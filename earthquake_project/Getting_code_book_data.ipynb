{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting variable description for Earthquake data\n",
    "\n",
    "I scrape the data from the Significant Earthquake Database of the National Centers for Environmental Information to make a code book with the variables obtained from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Accessing web page with information\n",
    "results = requests.get(\"http://www.ngdc.noaa.gov/nndc/struts/results?&t=101650&s=225&d=225\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "page_cont = results.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var_page = BeautifulSoup(page_cont, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Getting all the relavant links\n",
    "search_link = []\n",
    "for item in var_page.find_all(\"a\"):\n",
    "    get_link = item.get(\"onclick\").split(\",\")[0]\n",
    "    beginning = get_link.find(\"'\")\n",
    "    final_link = get_link[beginning + 1: -1]\n",
    "    search_link.append(final_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_link = \"http://www.ngdc.noaa.gov\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Accessing the links and getting all the information and writing it to a file.\n",
    "for link in search_link:\n",
    "    link_content = requests.get(base_link + link)\n",
    "    var_def = BeautifulSoup(link_content.content, \"html.parser\")\n",
    "    with open(\"var_description.txt\", \"a\") as var_desc:\n",
    "        var_desc.write(var_def.find(\"a\").text)\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_science_udemy]",
   "language": "python",
   "name": "conda-env-data_science_udemy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
